{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WijzJUfcbzmV"
   },
   "source": [
    "# Poems classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example about how to train a classifier of poems by topic or by form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `run_as_standalone_nb = True` if you are running this notebook outside of a clone of its repository (https://github.com/Poems-AI/AI.git). For example, in a Colab or Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:32.681825Z",
     "iopub.status.busy": "2022-02-09T21:55:32.681566Z",
     "iopub.status.idle": "2022-02-09T21:55:34.382241Z",
     "shell.execute_reply": "2022-02-09T21:55:34.381460Z",
     "shell.execute_reply.started": "2022-02-09T21:55:32.681790Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "run_as_standalone_nb = True\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if run_as_standalone_nb:\n",
    "    import sys    \n",
    "    root_lib_path = Path('AI').resolve()\n",
    "    if not root_lib_path.exists():\n",
    "        !git clone https://github.com/Poems-AI/AI.git\n",
    "    if str(root_lib_path) not in sys.path:\n",
    "        sys.path.insert(0, str(root_lib_path))\n",
    "        \n",
    "    !pip install transformers\n",
    "    !apt-get install git-lfs\n",
    "    !git lfs install\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:24.946712Z",
     "iopub.status.busy": "2022-02-09T21:55:24.946264Z",
     "iopub.status.idle": "2022-02-09T21:55:32.676501Z",
     "shell.execute_reply": "2022-02-09T21:55:32.675632Z",
     "shell.execute_reply.started": "2022-02-09T21:55:24.946661Z"
    },
    "id": "W6y8saYIIMjj"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from enum import auto, Enum\n",
    "from functools import partial\n",
    "from huggingface_hub import login, notebook_login\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from poemsai.nb_utils import commit_checkpoint_to_hf_hub, download_checkpoint_from_hf_hub\n",
    "import transformers\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding, \n",
    "                          Trainer, TrainingArguments)\n",
    "from transformers.optimization import SchedulerType\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone our datasets repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:35.989915Z",
     "iopub.status.busy": "2022-02-09T21:55:35.989492Z",
     "iopub.status.idle": "2022-02-09T21:55:55.129005Z",
     "shell.execute_reply": "2022-02-09T21:55:55.128206Z",
     "shell.execute_reply.started": "2022-02-09T21:55:35.989874Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Poems-AI/dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:55.131234Z",
     "iopub.status.busy": "2022-02-09T21:55:55.130935Z",
     "iopub.status.idle": "2022-02-09T21:55:55.137173Z",
     "shell.execute_reply": "2022-02-09T21:55:55.136452Z",
     "shell.execute_reply.started": "2022-02-09T21:55:55.131192Z"
    }
   },
   "outputs": [],
   "source": [
    "# Prevent wandb login requirement\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:55.138801Z",
     "iopub.status.busy": "2022-02-09T21:55:55.138519Z",
     "iopub.status.idle": "2022-02-09T21:55:55.168699Z",
     "shell.execute_reply": "2022-02-09T21:55:55.167904Z",
     "shell.execute_reply.started": "2022-02-09T21:55:55.138767Z"
    }
   },
   "outputs": [],
   "source": [
    "class LabelsType(Enum):\n",
    "    Forms = \"forms\"\n",
    "    Topics = \"topics\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose if you want to train a classifier of poems by form (`LabelsType.Forms`) or by topic (`LabelsType.Topics`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:55.172889Z",
     "iopub.status.busy": "2022-02-09T21:55:55.172346Z",
     "iopub.status.idle": "2022-02-09T21:55:55.177938Z",
     "shell.execute_reply": "2022-02-09T21:55:55.177133Z",
     "shell.execute_reply.started": "2022-02-09T21:55:55.172846Z"
    }
   },
   "outputs": [],
   "source": [
    "classify_by = LabelsType.Forms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Login to HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:55.180037Z",
     "iopub.status.busy": "2022-02-09T21:55:55.179262Z",
     "iopub.status.idle": "2022-02-09T21:55:55.186085Z",
     "shell.execute_reply": "2022-02-09T21:55:55.185436Z",
     "shell.execute_reply.started": "2022-02-09T21:55:55.179998Z"
    }
   },
   "outputs": [],
   "source": [
    "HF_USER = \"YOUR_HF_USER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 1: notebook_login.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 2: get token.** Unfortunately, you need to manually set your password. Every time you push to hub, you'll need to pass `use_auth_token=login_token`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd = 'YOUR_HF_PASSWORD'\n",
    "login_token = login(HF_USER, pwd)\n",
    "pwd = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Option 3 (recommended): interact with the git repo that stores your model** and pass the password every time you commit\n",
    "<br><br>\n",
    "Before commiting, you need to tell git your user and email (from HuggingFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:55.188376Z",
     "iopub.status.busy": "2022-02-09T21:55:55.187466Z",
     "iopub.status.idle": "2022-02-09T21:55:56.527800Z",
     "shell.execute_reply": "2022-02-09T21:55:56.526839Z",
     "shell.execute_reply.started": "2022-02-09T21:55:55.188338Z"
    }
   },
   "outputs": [],
   "source": [
    "HF_EMAIL = \"YOUR_HF_EMAIL\"\n",
    "!git config --global user.email $HF_EMAIL\n",
    "!git config --global user.name $HF_USER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can push to hub by calling `commit_checkpoint_to_hub`. For instance:\n",
    "```\n",
    "commit_checkpoint_to_hub('distilbert-poems-clf-by-form.en', HF_USER, './checkpoints/checkpoint-7170', \n",
    "                         message='Update model after 50 epochs', pwd='YOUR_HF_PASSWORD')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the same splits we used to train a simple generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:56.529700Z",
     "iopub.status.busy": "2022-02-09T21:55:56.529405Z",
     "iopub.status.idle": "2022-02-09T21:55:56.620324Z",
     "shell.execute_reply": "2022-02-09T21:55:56.619486Z",
     "shell.execute_reply.started": "2022-02-09T21:55:56.529662Z"
    }
   },
   "outputs": [],
   "source": [
    "splits_df_path = 'dataset/all.txt/en.txt/simple/all_poems.en.splits.csv'\n",
    "splits_df = pd.read_csv(splits_df_path, index_col=0)\n",
    "splits_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If outside of Kaggle, you should set `kaggle_ds_root` to the root folder that contains the poems dataset\n",
    "by Kaggle user michaelarman (https://www.kaggle.com/michaelarman/poemsdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:56.622070Z",
     "iopub.status.busy": "2022-02-09T21:55:56.621813Z",
     "iopub.status.idle": "2022-02-09T21:55:56.660789Z",
     "shell.execute_reply": "2022-02-09T21:55:56.660013Z",
     "shell.execute_reply.started": "2022-02-09T21:55:56.622036Z"
    }
   },
   "outputs": [],
   "source": [
    "kaggle_ds_root_placeholder = '[KAGGLE_DS_ROOT]'\n",
    "# If outside of Kaggle, replace with the path of a root folder that contains the poems dataset\n",
    "# by Kaggle user michaelarman (https://www.kaggle.com/michaelarman/poemsdataset)\n",
    "kaggle_ds_root = '/kaggle/input'\n",
    "kaggle_ds_splits_df = splits_df.copy()[\n",
    "    splits_df.Location.str.contains(f'/{classify_by.value}/', regex=False)\n",
    "    & splits_df.Location.str.contains(kaggle_ds_root_placeholder, regex=False)\n",
    "]\n",
    "kaggle_ds_splits_df.Location = kaggle_ds_splits_df.Location.str.replace(kaggle_ds_root_placeholder, \n",
    "                                                                        kaggle_ds_root,\n",
    "                                                                        regex=False)\n",
    "kaggle_ds_splits_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:56.662337Z",
     "iopub.status.busy": "2022-02-09T21:55:56.662018Z",
     "iopub.status.idle": "2022-02-09T21:55:56.679741Z",
     "shell.execute_reply": "2022-02-09T21:55:56.679129Z",
     "shell.execute_reply.started": "2022-02-09T21:55:56.662301Z"
    }
   },
   "outputs": [],
   "source": [
    "train_split_df = kaggle_ds_splits_df[kaggle_ds_splits_df.Split == 'Train']\n",
    "valid_split_df = kaggle_ds_splits_df[kaggle_ds_splits_df.Split == 'Validation']\n",
    "train_split_df, valid_split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:56.681253Z",
     "iopub.status.busy": "2022-02-09T21:55:56.680992Z",
     "iopub.status.idle": "2022-02-09T21:55:56.685835Z",
     "shell.execute_reply": "2022-02-09T21:55:56.685048Z",
     "shell.execute_reply.started": "2022-02-09T21:55:56.681220Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_content_of_file_path(path:str):\n",
    "    if not Path(path).exists():\n",
    "        # Some poems contain strange characters in the title that don't match \n",
    "        # the original poem name, but they are about 1% and some are in french \n",
    "        # or other languages, so we don't mind discarding them\n",
    "        #print('skipped ', path)\n",
    "        return ''\n",
    "    with open(path) as f:\n",
    "        return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:55:56.687853Z",
     "iopub.status.busy": "2022-02-09T21:55:56.686974Z",
     "iopub.status.idle": "2022-02-09T21:56:50.884076Z",
     "shell.execute_reply": "2022-02-09T21:56:50.883352Z",
     "shell.execute_reply.started": "2022-02-09T21:55:56.687817Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_to_labeled_df(split_df):\n",
    "    labeled_df = pd.DataFrame({\n",
    "        'text': split_df.Location.map(get_content_of_file_path), \n",
    "        'labels': split_df.Location.map(lambda path: Path(path).parent.name), \n",
    "    })\n",
    "    return labeled_df\n",
    "\n",
    "\n",
    "train_df = split_to_labeled_df(train_split_df)\n",
    "valid_df = split_to_labeled_df(valid_split_df)\n",
    "train_empty_selector = train_df.text == ''\n",
    "valid_empty_selector = valid_df.text == ''\n",
    "train_df = train_df[~train_empty_selector]\n",
    "valid_df = valid_df[~valid_empty_selector]\n",
    "train_df, valid_df, train_empty_selector.sum(), valid_empty_selector.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the number of poems by category:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:50.885615Z",
     "iopub.status.busy": "2022-02-09T21:56:50.885338Z",
     "iopub.status.idle": "2022-02-09T21:56:50.892585Z",
     "shell.execute_reply": "2022-02-09T21:56:50.891880Z",
     "shell.execute_reply.started": "2022-02-09T21:56:50.885583Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(train_df.labels.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:50.894335Z",
     "iopub.status.busy": "2022-02-09T21:56:50.893936Z",
     "iopub.status.idle": "2022-02-09T21:56:50.908509Z",
     "shell.execute_reply": "2022-02-09T21:56:50.907758Z",
     "shell.execute_reply.started": "2022-02-09T21:56:50.894300Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with pd.option_context('display.max_rows', None):\n",
    "    print(valid_df.labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[OPTIONAL]: set `min_poems_by_category` to a value greater than 1 to drop the poems whose category has less than `min_poems_by_category` training poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:50.912993Z",
     "iopub.status.busy": "2022-02-09T21:56:50.912792Z",
     "iopub.status.idle": "2022-02-09T21:56:50.987638Z",
     "shell.execute_reply": "2022-02-09T21:56:50.986835Z",
     "shell.execute_reply.started": "2022-02-09T21:56:50.912970Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "min_poems_by_category = 4\n",
    "train_df = train_df.groupby(by='labels').filter(lambda x: x.shape[0] >= min_poems_by_category)\n",
    "valid_df = valid_df.groupby(by='labels').filter(lambda x: x.name in train_df.labels.unique())\n",
    "labels = train_df.labels.unique()\n",
    "num_labels = len(labels)\n",
    "train_df, valid_df, num_labels, valid_df.labels.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export to csv in order to ease the load by datasets library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:50.989090Z",
     "iopub.status.busy": "2022-02-09T21:56:50.988784Z",
     "iopub.status.idle": "2022-02-09T21:56:51.244307Z",
     "shell.execute_reply": "2022-02-09T21:56:51.243590Z",
     "shell.execute_reply.started": "2022-02-09T21:56:50.989054Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds_path = 'train.csv'\n",
    "valid_ds_path = 'valid.csv'\n",
    "train_df.to_csv(train_ds_path)\n",
    "valid_df.to_csv(valid_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:51.245765Z",
     "iopub.status.busy": "2022-02-09T21:56:51.245533Z",
     "iopub.status.idle": "2022-02-09T21:56:51.994867Z",
     "shell.execute_reply": "2022-02-09T21:56:51.994152Z",
     "shell.execute_reply.started": "2022-02-09T21:56:51.245733Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "data_files = {\"train\": train_ds_path, \"validation\": valid_ds_path}\n",
    "raw_datasets = load_dataset(\"csv\", data_files=data_files)\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and numericalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:51.996574Z",
     "iopub.status.busy": "2022-02-09T21:56:51.996111Z",
     "iopub.status.idle": "2022-02-09T21:56:58.811825Z",
     "shell.execute_reply": "2022-02-09T21:56:58.811119Z",
     "shell.execute_reply.started": "2022-02-09T21:56:51.996534Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "checkpoint = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:58.813243Z",
     "iopub.status.busy": "2022-02-09T21:56:58.812982Z",
     "iopub.status.idle": "2022-02-09T21:56:58.818821Z",
     "shell.execute_reply": "2022-02-09T21:56:58.818090Z",
     "shell.execute_reply.started": "2022-02-09T21:56:58.813208Z"
    }
   },
   "outputs": [],
   "source": [
    "id2label = dict(enumerate(labels))\n",
    "label2id = {label: i for i, label in id2label.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:56:58.821080Z",
     "iopub.status.busy": "2022-02-09T21:56:58.820207Z",
     "iopub.status.idle": "2022-02-09T21:57:03.570242Z",
     "shell.execute_reply": "2022-02-09T21:57:03.569351Z",
     "shell.execute_reply.started": "2022-02-09T21:56:58.821037Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    result = tokenizer(examples[\"text\"], truncation=True)\n",
    "    result[\"labels\"] = [label2id[l] for l in examples[\"labels\"]]\n",
    "    return result\n",
    "columns_to_remove = [c for c in raw_datasets['train'].column_names if c != 'labels']\n",
    "tokenized_datasets = raw_datasets.map(preprocess_function, batched=True, remove_columns=columns_to_remove)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose a collator that dinamically pads the inputs to the length of the longest sequence in the batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:57:03.571971Z",
     "iopub.status.busy": "2022-02-09T21:57:03.571492Z",
     "iopub.status.idle": "2022-02-09T21:57:03.576808Z",
     "shell.execute_reply": "2022-02-09T21:57:03.575680Z",
     "shell.execute_reply.started": "2022-02-09T21:57:03.571928Z"
    }
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:57:03.579855Z",
     "iopub.status.busy": "2022-02-09T21:57:03.579393Z",
     "iopub.status.idle": "2022-02-09T21:57:03.603559Z",
     "shell.execute_reply": "2022-02-09T21:57:03.602603Z",
     "shell.execute_reply.started": "2022-02-09T21:57:03.579810Z"
    }
   },
   "outputs": [],
   "source": [
    "def freeze(params):\n",
    "    for p in params: p.requires_grad = False\n",
    "        \n",
    "def freeze_backbone(model):#:DistilBertForSequenceClassification):\n",
    "    freeze(model.distilbert.parameters())\n",
    "    \n",
    "def create_opt_disc_lrs(model, min_lr, max_lr, head_lr):\n",
    "    n_blocks = len(model.distilbert.transformer.layer)\n",
    "    lr_mult = (max_lr / min_lr) ** (1 / (n_blocks - 1))\n",
    "    blocks_lrs = [min_lr * lr_mult ** i for i in range(n_blocks)]\n",
    "    blocks_params = [{'params': model.distilbert.transformer.layer[i].parameters(), 'lr': blocks_lrs[i]}\n",
    "                     for i in range(n_blocks)]\n",
    "    return torch.optim.AdamW([\n",
    "        {'params': model.distilbert.embeddings.parameters(), 'lr': min_lr},\n",
    "        {'params': model.pre_classifier.parameters()}, #, 'lr': head_lr},\n",
    "        {'params': model.classifier.parameters()},#, 'lr': head_lr},\n",
    "        *blocks_params,\n",
    "    ], lr=head_lr, weight_decay=0, betas=(0.9, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T22:48:22.932813Z",
     "iopub.status.busy": "2022-02-09T22:48:22.932259Z",
     "iopub.status.idle": "2022-02-09T22:48:25.491190Z",
     "shell.execute_reply": "2022-02-09T22:48:25.490470Z",
     "shell.execute_reply.started": "2022-02-09T22:48:22.932776Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "custom_model_name = f'distilbert-poems-clf-by-{classify_by.value[:-1]}.en'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, \n",
    "    num_labels=num_labels,\n",
    "    id2label=id2label, \n",
    "    label2id=label2id,\n",
    "    #dropout=0.3,\n",
    "    #seq_classif_dropout=0.5,\n",
    "    #attention_dropout=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T21:57:15.282170Z",
     "iopub.status.busy": "2022-02-09T21:57:15.281901Z",
     "iopub.status.idle": "2022-02-09T21:57:15.286721Z",
     "shell.execute_reply": "2022-02-09T21:57:15.285911Z",
     "shell.execute_reply.started": "2022-02-09T21:57:15.282134Z"
    }
   },
   "outputs": [],
   "source": [
    "# Clone repo of our model to commit there later\n",
    "resume_training = False\n",
    "if resume_training:\n",
    "    hf_pwd = 'YOUR_HF_PASSWORD'\n",
    "    download_checkpoint_from_hf_hub(custom_model_name, HF_USER, hf_pwd)\n",
    "    hf_pwd = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: create your own optimizer. In case you choose to use it, don't forget to uncomment the line that passes the optimizer to the `Trainer` constructor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T18:38:44.052021Z",
     "iopub.status.busy": "2022-02-09T18:38:44.051218Z",
     "iopub.status.idle": "2022-02-09T18:38:44.060091Z",
     "shell.execute_reply": "2022-02-09T18:38:44.059409Z",
     "shell.execute_reply.started": "2022-02-09T18:38:44.051968Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "opt = create_opt_disc_lrs(model, 1e-7, 2e-5, 5e-5)\n",
    "[(len(pg['params']), pg['lr']) for pg in opt.param_groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Optional]: freeze some layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T18:38:52.278297Z",
     "iopub.status.busy": "2022-02-09T18:38:52.277843Z",
     "iopub.status.idle": "2022-02-09T18:38:52.289022Z",
     "shell.execute_reply": "2022-02-09T18:38:52.288267Z",
     "shell.execute_reply.started": "2022-02-09T18:38:52.278259Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "freeze_backbone(model)\n",
    "sum(1 for p in model.parameters() if p.requires_grad), sum(1 for p in model.parameters() if not p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T22:49:20.875455Z",
     "iopub.status.busy": "2022-02-09T22:49:20.875108Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds, expect_preds=False):\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1).reshape(-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./checkpoints\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=20,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=transformers.trainer_utils.IntervalStrategy.EPOCH,  \n",
    "    save_strategy=transformers.trainer_utils.IntervalStrategy.EPOCH,\n",
    "    lr_scheduler_type=transformers.trainer_utils.SchedulerType.CONSTANT,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    #optimizers=(opt, None),\n",
    ")\n",
    "\n",
    "trainer.train(resume_from_checkpoint=custom_model_name if resume_training else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T04:58:53.353198Z",
     "iopub.status.busy": "2022-02-09T04:58:53.352411Z",
     "iopub.status.idle": "2022-02-09T04:58:54.182576Z",
     "shell.execute_reply": "2022-02-09T04:58:54.181487Z",
     "shell.execute_reply.started": "2022-02-09T04:58:53.353119Z"
    }
   },
   "outputs": [],
   "source": [
    "!ls -l checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-09T01:50:10.498239Z",
     "iopub.status.busy": "2022-02-09T01:50:10.497734Z",
     "iopub.status.idle": "2022-02-09T01:50:10.508689Z",
     "shell.execute_reply": "2022-02-09T01:50:10.507304Z",
     "shell.execute_reply.started": "2022-02-09T01:50:10.498188Z"
    }
   },
   "outputs": [],
   "source": [
    "last_checkpoint = get_last_checkpoint('./checkpoints')\n",
    "custom_model_name, last_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-08T23:05:14.003615Z",
     "iopub.status.busy": "2022-02-08T23:05:14.003326Z",
     "iopub.status.idle": "2022-02-08T23:06:33.146699Z",
     "shell.execute_reply": "2022-02-08T23:06:33.145778Z",
     "shell.execute_reply.started": "2022-02-08T23:05:14.003577Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "commit_checkpoint_to_hf_hub(custom_model_name, HF_USER, last_checkpoint,\n",
    "                            message='Add model, 20 epochs', pwd='YOUR_HF_PASSWORD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
