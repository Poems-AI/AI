{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WijzJUfcbzmV"
   },
   "source": [
    "# Evaluation of conditional generators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks serves as a tool to evaluate the conditioning quality of a text generator using a text classifier.\n",
    "\n",
    "It assumes the generator is able to use the first word of an input sequence as a label that conditions the characteristics of the output text.\n",
    "\n",
    "We construct the prompts fed to the generator in two different ways, which results in four different metrics, as we calculate the validation loss and accuracy for each procedure.\n",
    "\n",
    "**Procedure A**\n",
    "\n",
    "1. Generate text using just the labels plus a line break as prompt (one label per input sequence, as many sequences as labels).\n",
    "2. Delete the labels from the generated text.\n",
    "3. Feed the generated text to the corresponding classifier to evaluate the metrics.\n",
    "\n",
    "**Procedure B**\n",
    "\n",
    "1. Generate text using as prompt an initial substring of each sequence in the validation set, with its label and a line break prepended. We are limiting the length of prompt to the minimum between 100 characters and 1/4 of the length of the text.\n",
    "2. Delete the labels from the generated text.\n",
    "3. Feed the generated text to the corresponding classifier to evaluate the metrics.\n",
    "\n",
    "The dataset/split used in this case is the same dataset that we use as validation set to train the text classifier (see [train_poems_classifier.ipynb](train_poems_classifier.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `run_as_standalone_nb = True` if you are running this notebook outside of a clone of its repository (https://github.com/Poems-AI/AI.git). For example, in a Colab or Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r  ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_as_standalone_nb = False\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if run_as_standalone_nb:\n",
    "    import sys    \n",
    "    root_lib_path = Path('AI').resolve()\n",
    "    if not root_lib_path.exists():\n",
    "        !git clone https://github.com/Poems-AI/AI.git\n",
    "    if str(root_lib_path) not in sys.path:\n",
    "        sys.path.insert(0, str(root_lib_path))\n",
    "        \n",
    "    !pip install happytransformer\n",
    "    !pip install transformers\n",
    "    !pip install \"torch>=1.10\"\n",
    "    !apt-get install git-lfs\n",
    "    !git lfs install\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6y8saYIIMjj"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import AutoModelForCausalLM, AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poemsai.config import set_config_value\n",
    "from poemsai.data import (build_labeled_dfs_from_splits, label_type_to_str, LabelsType, LabelsWriterStd, \n",
    "                          PoemsFileConfig)\n",
    "from poemsai.metrics import ConditionalGenEvaluator\n",
    "from poemsai.nb_utils import download_checkpoint_from_hf_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone our datasets repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Poems-AI/dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the type of labels the generator must be conditioned on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_type = LabelsType.Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_USER = 'YOUR_HF_USER'\n",
    "gen_model_name = 'gpt2-poems-endtags.en'\n",
    "cat_name = label_type_to_str(labels_type)\n",
    "clf_model_name = f'distilbert-poems-clf-by-{cat_name}'\n",
    "hf_pwd = 'YOUR_HF_PASSWORD'\n",
    "download_checkpoint_from_hf_hub(gen_model_name, HF_USER, hf_pwd)\n",
    "download_checkpoint_from_hf_hub(clf_model_name, HF_USER, hf_pwd)\n",
    "hf_pwd = None\n",
    "gen_model = AutoModelForCausalLM.from_pretrained(gen_model_name)\n",
    "clf_model = AutoModelForSequenceClassification.from_pretrained(clf_model_name)\n",
    "gen_tokenizer = AutoTokenizer.from_pretrained(gen_model_name)\n",
    "clf_tokenizer = AutoTokenizer.from_pretrained(clf_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must use the same file config and the same `BaseLabelsWriter` subclass that you used to generate the text file that was used to train `gen_model_name`.\n",
    "\n",
    "This way, the prompts fed to the generator will have the same format as the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_conf = PoemsFileConfig.from_json('dataset/all.txt/en.txt/only_end_tags/all_poems.en.conf.json')\n",
    "all_cats_ordered = [label_type_to_str(cat) for cat in LabelsType if cat != LabelsType.All]\n",
    "evaluator = ConditionalGenEvaluator(gen_model, gen_tokenizer, clf_model, clf_tokenizer, file_conf,\n",
    "                                    cat_name, all_cats_ordered, labels_writer=LabelsWriterStd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics A\n",
    "\n",
    "These metrics are referred to as \"*[label_type] conditional loss A*\" and \"*[label_type] conditional accuracy A*\" in the [results doc](../docs/results.md), with \"[label_type]\" being one of {\"topic\", \"form\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.eval_with_labels_as_prompt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics B\n",
    "\n",
    "These metrics are referred to as \"*[label_type] conditional loss B*\" and \"*[label_type] conditional accuracy B*\" in the [results doc](../docs/results.md), with \"[label_type]\" being one of {\"topic\", \"form\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If outside of Kaggle, you should point `KAGGLE_DS_ROOT` to the root folder that contains the poems dataset\n",
    "by Kaggle user michaelarman (https://www.kaggle.com/michaelarman/poemsdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config_value('KAGGLE_DS_ROOT', '/kaggle/input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_df_path = 'dataset/all.txt/en.txt/only_end_tags/all_poems.en.splits.csv'\n",
    "splits_df = pd.read_csv(splits_df_path, index_col=0)\n",
    "_, valid_df = build_labeled_dfs_from_splits(splits_df, labels_type)\n",
    "evaluator.eval_with_seq_fragment_as_prompt(valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
