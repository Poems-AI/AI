{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeled inputs generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks generates the text files we are using to train our conditional poems generators. It only supports english as language, given that we only have labels in an english poems dataset.\n",
    "\n",
    "At the end, two text files are generated in the current directory:\n",
    "* A concatenation of all the poems of the training set, with name `all_poems.labeled.by_[cat].train.[lang].txt`\n",
    "* A concatenation of all the poems of the validation set, with name `all_poems.labeled.by_[cat].valid.[lang].txt`\n",
    "\n",
    "Each poem is labeled by prepending an additional verse with its category (form or topic).\n",
    "\n",
    "There are two additional files that you need to preserve, which we just copy to the current directory, from an unconditional generator source data files:\n",
    "* A JSON file with the formatting configuration chosen, with name `all_poems.[lang].conf.json`\n",
    "* A csv file with the assignment of poems to splits, with name `all_poems.[lang].splits.csv`\n",
    "\n",
    "It is because we want to have a comparable baseline that we copy the splits and format used to train an unconditional poems generator, that we had previously saved in our datasets repo.\n",
    "\n",
    "Anyway, you can use a different file structure by defining your own `PoemsFileConfig` instance and passing it to `LabeledPoemsIOWriter.__init__` method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `run_as_standalone_nb = True` if you are running this notebook outside of a clone of its repository (https://github.com/Poems-AI/AI.git). For example, in a Colab or Kaggle notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_as_standalone_nb = False\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "if run_as_standalone_nb:\n",
    "    import sys    \n",
    "    root_lib_path = Path('AI').resolve()\n",
    "    if not root_lib_path.exists():\n",
    "        !git clone https://github.com/Poems-AI/AI.git\n",
    "    if str(root_lib_path) not in sys.path:\n",
    "        sys.path.insert(0, str(root_lib_path))\n",
    "        \n",
    "    !pip install -r {root_lib_path/'requirements.txt'}\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T19:30:45.343205Z",
     "iopub.status.busy": "2022-02-14T19:30:45.342967Z",
     "iopub.status.idle": "2022-02-14T19:30:52.779539Z",
     "shell.execute_reply": "2022-02-14T19:30:52.778900Z",
     "shell.execute_reply.started": "2022-02-14T19:30:45.343175Z"
    },
    "id": "W6y8saYIIMjj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from poemsai.data import (DataSource, get_ds_root_placeholder,  LabeledPoemsSplitsDfReader, \n",
    "                          LabeledPoemsIOWriter, LabelsEstimator, LabelsType, label_type_to_str, \n",
    "                          LabelsWriterStd, LabelsWriterKeyValue, LabelsWriterKeyValueMultiverse, \n",
    "                          LabelsWriterExplained, PoemsFileConfig, PoemsSplitsDfContentReader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clone our datasets repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-14T19:30:53.231452Z",
     "iopub.status.busy": "2022-02-14T19:30:53.231218Z",
     "iopub.status.idle": "2022-02-14T19:31:05.809403Z",
     "shell.execute_reply": "2022-02-14T19:31:05.808698Z",
     "shell.execute_reply.started": "2022-02-14T19:30:53.231428Z"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Poems-AI/dataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose: if you want to label the poems with its form (`LabelsType.Forms`) or by topic (`LabelsType.Topics`). \n",
    "\n",
    "Note that the poems chosen are different depending on the label type unless you choose `LabelsType.All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T01:32:03.220013Z",
     "iopub.status.busy": "2022-02-13T01:32:03.219737Z",
     "iopub.status.idle": "2022-02-13T01:32:03.226923Z",
     "shell.execute_reply": "2022-02-13T01:32:03.226291Z",
     "shell.execute_reply.started": "2022-02-13T01:32:03.219969Z"
    }
   },
   "outputs": [],
   "source": [
    "label_with = LabelsType.All"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set `fill_missing_labels = True` if you want the unknown labels to be estimated by classifiers. It only has an effect if `label_with` is `LabelsType.All`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_missing_labels = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text files generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('dataset/all.txt/en.txt/only_end_tags/')\n",
    "splits_df_path = data_path/'all_poems.en.splits.csv'\n",
    "splits_df = pd.read_csv(splits_df_path, index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If outside of Kaggle, you should set `kaggle_ds_root` to the root folder that contains the poems dataset\n",
    "by Kaggle user michaelarman (https://www.kaggle.com/michaelarman/poemsdataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T01:33:06.583608Z",
     "iopub.status.busy": "2022-02-13T01:33:06.583128Z",
     "iopub.status.idle": "2022-02-13T01:33:06.721643Z",
     "shell.execute_reply": "2022-02-13T01:33:06.720737Z",
     "shell.execute_reply.started": "2022-02-13T01:33:06.583558Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "kaggle_ds_root = '/kaggle/input'\n",
    "own_ds_root = './dataset'\n",
    "kaggle_ds_root_placeholder = get_ds_root_placeholder(DataSource.Kaggle)\n",
    "own_ds_root_placeholder = get_ds_root_placeholder(DataSource.Marcos)\n",
    "\n",
    "\n",
    "def filter_df(df, labels_type, split):\n",
    "    labels_type_filter = f'/{labels_type.value}/' if labels_type != LabelsType.All else ''\n",
    "    kaggle_filter = kaggle_ds_root_placeholder if labels_type != LabelsType.All else ''\n",
    "    return df.copy()[\n",
    "        df.Location.str.contains(labels_type_filter, regex=False)\n",
    "        & df.Location.str.contains(kaggle_filter, regex=False)\n",
    "        & (df.Split == split)        \n",
    "    ]\n",
    "\n",
    "\n",
    "def replace_location_placeholder(df):\n",
    "    df.Location = df.Location.str.replace(kaggle_ds_root_placeholder, \n",
    "                                          kaggle_ds_root,\n",
    "                                          regex=False)\n",
    "    df.Location = df.Location.str.replace(own_ds_root_placeholder, \n",
    "                                          own_ds_root,\n",
    "                                          regex=False)\n",
    "    return df\n",
    "\n",
    "    \n",
    "kaggle_ds_train_split_df = replace_location_placeholder(filter_df(splits_df, label_with, 'Train'))\n",
    "kaggle_ds_valid_split_df = replace_location_placeholder(filter_df(splits_df, label_with, 'Validation'))\n",
    "kaggle_ds_train_split_df, kaggle_ds_valid_split_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the proper labels writer class depending on how you want the poems to be tagged with the labels:\n",
    "- `LabelsWriterStd`: include a verse for every label, '?' if the label for a category isn't available. For instance:\n",
    "    form: ? \\n<br>\n",
    "    topic: beach \\n <br>\n",
    "    Verse 1 \\n\n",
    "- `LabelsWriterKeyValue`: include one verse with all the labels, with \"key: value\" format, '?' if the label for a category isn't available. For instance:<br>\n",
    "    form: sonnet, topic: love \\n<br>\n",
    "    Verse 1 \\n\n",
    "- `LabelsWriterKeyValueMultiverse`: include a verse for every label, with \"key: value\" format, '?' if the label for a category isn't available. For instance:<br>\n",
    "    form: sonnet \\n<br>\n",
    "    topic: love \\n<br>\n",
    "    Verse 1 \\n\n",
    "- `LabelsWriterExplained`: include a verse with a description of the labels, '?' if the label for a category isn't available. For instance:<br>\n",
    "    This is a poem with sonnet form about love: \\n<br>\n",
    "    Verse 1 \\n\n",
    "- `LabelsWriterExplained(omit_empty=True)`: include a verse with a description of the labels, not including anything for categories not available. For instance (assume form is not available):<br>\n",
    "    This is a poem about love: \\n<br>\n",
    "    Verse 1 \\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_writer = LabelsWriterExplained()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-13T01:39:50.665799Z",
     "iopub.status.busy": "2022-02-13T01:39:50.664811Z",
     "iopub.status.idle": "2022-02-13T01:39:50.845286Z",
     "shell.execute_reply": "2022-02-13T01:39:50.844421Z",
     "shell.execute_reply.started": "2022-02-13T01:39:50.665734Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "file_conf_path = data_path/'all_poems.en.conf.json'\n",
    "labels_type_str = label_type_to_str(label_with)\n",
    "\n",
    "\n",
    "def get_labels_writer_desc(labels_writer):\n",
    "    if isinstance(labels_writer, LabelsWriterStd):\n",
    "        return ''\n",
    "    if isinstance(labels_writer, LabelsWriterKeyValue):\n",
    "        return '_kv'\n",
    "    if isinstance(labels_writer, LabelsWriterKeyValueMultiverse):\n",
    "        return '_kv_mv'\n",
    "    if isinstance(labels_writer, LabelsWriterExplained):\n",
    "        return '_exp' if not labels_writer.omit_empty else '_exp_s'\n",
    "\n",
    "\n",
    "labels_estimator = LabelsEstimator('gpt2', 'YOUR_HF_USER', 'YOUR_HF_ACCESS_TOKEN') if fill_missing_labels else None\n",
    "poem_content_reader = PoemsSplitsDfContentReader()\n",
    "\n",
    "\n",
    "def label_func_multi(location:str):\n",
    "    labels = dict()\n",
    "    for cat in LabelsType:\n",
    "        if cat == LabelsType.All: continue\n",
    "        cat_str = label_type_to_str(cat)\n",
    "        if f'/{cat.value}/' in location:\n",
    "            labels[cat_str] = Path(location).parent.name  \n",
    "        elif fill_missing_labels:\n",
    "            poem_lines = poem_content_reader.extract_poem_lines(location)\n",
    "            labels[cat_str] = labels_estimator.predict(cat, poem_lines) if len(poem_lines) > 0 else ''\n",
    "        else:\n",
    "            labels[cat_str] = ''\n",
    "    return labels\n",
    "\n",
    "\n",
    "label_func = label_func_multi if label_with == LabelsType.All else None\n",
    "\n",
    "readers = [\n",
    "    LabeledPoemsSplitsDfReader(df, label_func=label_func) \n",
    "    for df in (kaggle_ds_train_split_df, kaggle_ds_valid_split_df)\n",
    "]\n",
    "split_names = ['train', 'valid']\n",
    "lw_desc = get_labels_writer_desc(labels_writer)\n",
    "fill_flag = '_filled' if fill_missing_labels else ''\n",
    "\n",
    "for split_name, reader in zip(split_names, readers):\n",
    "    labeled_poems_file_path = f'./all_poems.labeled.by_{labels_type_str}{lw_desc}{fill_flag}.{split_name}.en.txt'\n",
    "    with open(labeled_poems_file_path, 'w', encoding='utf-8') as out_file:\n",
    "        writer = LabeledPoemsIOWriter(\n",
    "            out_file, \n",
    "            PoemsFileConfig.from_json(file_conf_path),\n",
    "            labels_writer=labels_writer,\n",
    "        )\n",
    "        for labeled_poem in reader:\n",
    "            writer.write_poem(labeled_poem)\n",
    "\n",
    "!cp $splits_df_path .\n",
    "!cp $file_conf_path ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
