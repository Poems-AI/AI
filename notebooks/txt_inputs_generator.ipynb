{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks gathers, splits and preprocess the data we are using to train our poems generator.\n",
    "\n",
    "At the end, it generates three text files in the current directory:\n",
    "* A concatenation of all the poems of the training set, with name `all_poems.train.[lang].txt`\n",
    "* A concatenation of all the poems of the validation set, with name `all_poems.valid.[lang].txt`\n",
    "* A JSON file with the formatting configuration chosen, with name `all_poems.[lang].conf.json`\n",
    "* A csv file with the assignment of poems to splits, with name `all_poems.[lang].splits.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are trying to run the notebook outside of the project it belongs to (*https://github.com/Poems-AI/AI.git*), you need to set `run_as_standalone_nb = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_as_standalone_nb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_as_standalone_nb:\n",
    "    root_lib_path = Path('ai').resolve()\n",
    "    if not root_lib_path.exists():\n",
    "        !git clone https://github.com/Poems-AI/AI.git\n",
    "    if str(root_lib_path) not in sys.path:\n",
    "        sys.path.insert(0, str(root_lib_path))\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poemsai.config import set_config_value\n",
    "from poemsai.data import (ComposedPoemsReader, DataSource, data_splits_to_df, get_data_sources, \n",
    "                          Lang, lang_to_str, merge_poems, PoemsFileConfig, PoemsFileWriter, \n",
    "                          ReaderFactory, SplitterFactory, VerseGrouping)\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the cell below to choose the language you want to generate the .txt for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang.English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If outside of Kaggle, you should point the `'KAGGLE_DS_ROOT'` config key to the root folder that contains the Kaggle datasets you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config_value('KAGGLE_DS_ROOT', '/kaggle/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently using:\n",
    "* https://github.com/Poems-AI/dataset/tree/main/marcos_de_la_fuente.txt/en.txt: english poems by our poet Marcos de la Fuente\n",
    "* https://github.com/Poems-AI/dataset/tree/main/marcos_de_la_fuente.txt/es.txt: spanish poems by our poet Marcos de la Fuente\n",
    "* https://www.kaggle.com/michaelarman/poemsdataset) as an external english poetry dataset\n",
    "* https://www.kaggle.com/andreamorgar/spanish-poetry-dataset) as an external spanish poetry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/Poems-AI/dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = [get_data_sources(lang, ds_type) for ds_type in DataSource]\n",
    "[(type(ds), len(ds)) for ds in data_sources]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the percentage of data to be used as validation set, given as a fraction of unity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pct = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = [], []\n",
    "splitter_factory = SplitterFactory()\n",
    "\n",
    "for data_source in data_sources:\n",
    "    splitter = splitter_factory.get_splitter_for(data_source)\n",
    "    train_data_source, valid_data_source = splitter.split(data_source, valid_pct)\n",
    "    train_data.append(train_data_source)\n",
    "    valid_data.append(valid_data_source)\n",
    "    \n",
    "sum(len(ds) for ds in train_data), sum(len(ds) for ds in valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the metadata of splits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lang_str = lang_to_str(lang)\n",
    "csv_splits_path = Path(f'all_poems.{lang_str}.splits.csv')\n",
    "data_splits_to_df([\n",
    "    (train_data, 'Train'),\n",
    "    (valid_data, 'Validation')\n",
    "]).to_csv(csv_splits_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and merge poems by split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose how to format the poems by editting the init parameters of `write_conf`:\n",
    "* remove_multispaces: reduce sequences of spaces to just one space character\n",
    "* beginning_of_verse_token: token to include before the content of each verse\n",
    "* end_of_verse_token: token to include after the content of each verse\n",
    "* end_of_poem_token: token to include after the last `end_of_verse_token` of each poem\n",
    "* n_prev_verses_terminations: the last word of each of the `n_prev_verses_terminations` previous verses is prepended to each verse, before `beginning_of_verse_token`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_conf = PoemsFileConfig(remove_multispaces = True, \n",
    "                             beginning_of_verse_token = '',\n",
    "                             end_of_verse_token = '\\\\n', \n",
    "                             end_of_poem_token = '',\n",
    "                             n_prev_verses_terminations = 0, \n",
    "                             verse_grouping = VerseGrouping.OneVerseBySequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_factory = ReaderFactory()\n",
    "train_data_readers = [reader_factory.get_reader_for(data) for data in train_data]\n",
    "valid_data_readers = [reader_factory.get_reader_for(data) for data in valid_data]\n",
    "\n",
    "train_txt_path = Path(f'./all_poems.train.{lang_str}.txt')\n",
    "valid_txt_path = Path(f'./all_poems.valid.{lang_str}.txt')\n",
    "file_conf_json_path = Path(f'./all_poems.{lang_str}.conf.json')\n",
    "with open(train_txt_path, \"w\", encoding=\"utf-8\") as train_txt_f:\n",
    "    merge_poems(ComposedPoemsReader(train_data_readers), PoemsFileWriter(train_txt_f, write_conf))\n",
    "with open(valid_txt_path, \"w\", encoding=\"utf-8\") as valid_txt_f:\n",
    "    merge_poems(ComposedPoemsReader(valid_data_readers), PoemsFileWriter(valid_txt_f, write_conf))\n",
    "write_conf.save(file_conf_json_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the number of lines by file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l $train_txt_path\n",
    "!wc -l $valid_txt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
