{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks gathers, splits and preprocess the data we are using to train our poems generator.\n",
    "\n",
    "At the end, it generates two text files in the current directory:\n",
    "* A concatenation of all the poems of the training set, with name `all_poems.train.[lang].txt\n",
    "* A concatenation of all the poems of the validation set, with name `all_poems.valid.[lang].txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are trying to run the notebook outside of the project it belongs to (*https://github.com/Poems-AI/AI.git*), you need to set `run_as_standalone_nb = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_as_standalone_nb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_as_standalone_nb:\n",
    "    root_lib_path = Path('ai').resolve()\n",
    "    if not root_lib_path.exists():\n",
    "        !git clone https://github.com/Poems-AI/AI.git\n",
    "    if str(root_lib_path) not in sys.path:\n",
    "        sys.path.insert(0, str(root_lib_path))\n",
    "else:\n",
    "    import local_lib_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from poemsai.config import set_config_value\n",
    "from poemsai.data import (ComposedPoemsReader, DataSource, get_data_sources, Lang, lang_to_str, \n",
    "                          merge_poems, PoemsWriter, ReaderFactory, SplitterFactory)\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit the cell below to choose the language you want to generate the .txt for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = Lang.English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If outside of Kaggle, you should point the `'KAGGLE_DS_ROOT'` config key to the root folder that contains the Kaggle datasets you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_config_value('KAGGLE_DS_ROOT', '/kaggle/input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are currently using:\n",
    "* https://github.com/Poems-AI/dataset/tree/main/marcos_de_la_fuente.txt/en.txt: english poems by our poet Marcos de la Fuente\n",
    "* https://github.com/Poems-AI/dataset/tree/main/marcos_de_la_fuente.txt/es.txt: spanish poems by our poet Marcos de la Fuente\n",
    "* https://www.kaggle.com/michaelarman/poemsdataset) as an external english poetry dataset\n",
    "* https://www.kaggle.com/andreamorgar/spanish-poetry-dataset) as an external spanish poetry dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/Poems-AI/dataset.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sources = [get_data_sources(lang, ds_type) for ds_type in DataSource]\n",
    "[(type(ds), len(ds)) for ds in data_sources]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training and validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the percentage of data to be used as validation set, given as a fraction of unity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_pct = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data = [], []\n",
    "splitter_factory = SplitterFactory()\n",
    "\n",
    "for data_source in data_sources:\n",
    "    splitter = splitter_factory.get_splitter_for(data_source)\n",
    "    train_data_source, valid_data_source = splitter.split(data_source, valid_pct)\n",
    "    train_data.append(train_data_source)\n",
    "    valid_data.append(valid_data_source)\n",
    "    \n",
    "sum(len(ds) for ds in train_data), sum(len(ds) for ds in valid_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and merge poems by split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader_factory = ReaderFactory()\n",
    "train_data_readers = [reader_factory.get_reader_for(data) for data in train_data]\n",
    "valid_data_readers = [reader_factory.get_reader_for(data) for data in valid_data]\n",
    "\n",
    "train_txt_path = Path(f'./all_poems.train.{lang_to_str(lang)}.txt')\n",
    "valid_txt_path = Path(f'./all_poems.valid.{lang_to_str(lang)}.txt')\n",
    "with open(train_txt_path, \"w\", encoding=\"utf-8\") as train_txt_f:\n",
    "    merge_poems(ComposedPoemsReader(train_data_readers), PoemsWriter(train_txt_f))\n",
    "with open(valid_txt_path, \"w\", encoding=\"utf-8\") as valid_txt_f:\n",
    "    merge_poems(ComposedPoemsReader(valid_data_readers), PoemsWriter(valid_txt_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the number of lines by file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc -l $train_txt_path\n",
    "!wc -l $valid_txt_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
